{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-05T17:05:16.305508Z",
     "start_time": "2025-01-05T17:05:16.294372Z"
    }
   },
   "source": [
    "import json\n",
    "import torch\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from keybert import KeyBERT\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity as tfidf_cosine_similarity\n",
    "from torch.nn.functional import cosine_similarity"
   ],
   "outputs": [],
   "execution_count": 47
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-05T17:05:16.320626Z",
     "start_time": "2025-01-05T17:05:16.311549Z"
    }
   },
   "source": [
    "# A EXECUTER LORSQUE LES KEYWORD N'ONT JAMAIS ETE EXTRAITS\n",
    "# Récupère les documents du json\n",
    "# \n",
    "\n",
    "\n",
    "\n",
    "# documents = []\n",
    "# with open(\"./data/documents.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "#     documents = json.load(f)\n",
    "# \n",
    "# # Extraction de mots-clés\n",
    "# keywords_modele = KeyBERT()\n",
    "# \n",
    "# for doc in documents:\n",
    "#     texte = f\"{doc.get('title_s', '')} {doc.get('abstract_s', '')}\"\n",
    "#     keywords = keywords_modele.extract_keywords(texte, keyphrase_ngram_range=(1, 3), top_n=5) \n",
    "#     doc['extracted_keywords'] = [kw[0] for kw in keywords]  # Ajouter les mots-clés\n",
    "\n",
    "# #Une fois les doc changé on les sauvegarde pour pas avoir a reexcuters les cellules\n",
    "# with open(\"./data/documentsExtractedKey.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "#     json.dump(documents, f, indent=4, ensure_ascii=False)"
   ],
   "outputs": [],
   "execution_count": 48
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-05T17:05:16.552665Z",
     "start_time": "2025-01-05T17:05:16.382766Z"
    }
   },
   "source": [
    "# A EXECUTER LORSQUE \"./data/documentsExtractedKey.json\" EXISTE DEJA\n",
    "# Récupère les documents du json\n",
    "\n",
    "documents = []\n",
    "with open(\"./data/documentsExtractedKeywords.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    documents = json.load(f)\n",
    "    \n",
    "# Afficher un exemple de document\n",
    "print(documents[0])\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'title_s': ['Fractal inverse problem: an analytical approach'], 'abstract_s': ['Fractal inverse problem: The fractal inverse problem is an important research area with a great number of potential application fields. It constists in finding a fractal model or code that generates a given object. This concept has been introduced by Barnsley with the well known collage theorem [Bar88]. When the considered object is an image, we often speak about fractal image compression. A method has been proposed by Jacquin to solve this kind of inverse problem [Jac92].'], 'authFullName_s': ['Eric Guérin', 'Eric Tosan'], 'producedDateY_i': 2004, 'keyword_s': [''], 'extracted_keywords': ['fractal inverse problem', 'inverse problem fractal', 'approach fractal inverse', 'fractal inverse', 'problem fractal inverse']}\n"
     ]
    }
   ],
   "execution_count": 49
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-05T17:05:19.608958Z",
     "start_time": "2025-01-05T17:05:16.614443Z"
    }
   },
   "source": [
    "# Chargement du modèle\n",
    "modele = SentenceTransformer('multi-qa-mpnet-base-dot-v1')\n",
    "\n",
    "# Extraction des informations des documents\n",
    "informations = [\n",
    "    f\"{doc.get('title_s', '')} \"  # Titre\n",
    "    f\"{', '.join(doc.get('keyword_s', []))} \"  # Mots-clés\n",
    "    f\"{', '.join(doc.get('extracted_keywords', []))} \"  # Mots-clés extraits\n",
    "    f\"Auteurs: {', '.join(doc.get('authFullName_s', []))} \"  # Auteurs\n",
    "    for doc in documents\n",
    "]"
   ],
   "outputs": [],
   "execution_count": 50
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-05T17:05:55.522457Z",
     "start_time": "2025-01-05T17:05:19.689775Z"
    }
   },
   "source": [
    "# Générer les embeddings\n",
    "embeddings = modele.encode(informations, convert_to_tensor=True)\n",
    "\n",
    "# Associer chaque embedding à son document\n",
    "documents_valides = [doc for doc, titre in zip(documents, informations) if titre.strip()]\n",
    "documents_embeddings = [\n",
    "    {\"document\": doc, \"embedding\": embedding}\n",
    "    for doc, embedding in zip(documents_valides, embeddings)\n",
    "]\n",
    "\n",
    "# Calculer la similarité cosinus entre les embeddings\n",
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 3))\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(informations)"
   ],
   "outputs": [],
   "execution_count": 51
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-05T17:05:55.599359Z",
     "start_time": "2025-01-05T17:05:55.586155Z"
    }
   },
   "source": [
    "# Fonction qui cherche les documents les plus pertinents pour une requête\n",
    "def recherche(query, tfidf_vectorizer, tfidf_matrix, embeddings, documents, model):\n",
    "    # Si la requête contient des mots-clés, on effectue une recherche par mots-clés\n",
    "    if detecter_recherche_par_mots_cles(query):\n",
    "        return [res[0] for res in recherche_par_mots_cles(query, documents)]\n",
    "    else:\n",
    "        return recherche_hybride(query, tfidf_vectorizer, tfidf_matrix, embeddings, documents, model)\n",
    "\n",
    "# Fonction qui permet de détecter si la requête est une recherche par mots-clés\n",
    "def detecter_recherche_par_mots_cles(query):\n",
    "    termes_indicateurs = [\"liés à\", \"documents sur\", \"articles sur\", \"mots-clés\", \"thème\", \"traitent de\", \"traitant de\", \"concernant\", \"par rapport à\"]\n",
    "    return any(terme in query.lower() for terme in termes_indicateurs)\n",
    "\n",
    "# Fonction qui recherche les documents par mots-clés\n",
    "def recherche_par_mots_cles(query, documents):\n",
    "    resultats = []\n",
    "    for doc in documents:\n",
    "        mots_cles = doc.get('keyword_s', []) + doc.get('extracted_keywords', []) # On se concentre sur tous les mots-clés\n",
    "        similarite = sum(1 for mot in mots_cles if mot.lower() in query.lower())\n",
    "        if similarite > 0:\n",
    "            resultats.append((doc, similarite))\n",
    "    return sorted(resultats, key=lambda x: x[1], reverse=True)[:10]  # Trier par pertinence\n",
    "\n",
    "# Fonction qui recherche les documents avec une combinaison de similarité sémantique et TF-IDF\n",
    "def recherche_hybride(query, tfidf_vectorizer, tfidf_matrix, embeddings, documents, model):\n",
    "    # Recherche sémantique avec embeddings\n",
    "    query_embedding = model.encode(query, convert_to_tensor=True)\n",
    "    similarites_sémantiques = cosine_similarity(query_embedding, embeddings)\n",
    "    \n",
    "    # Recherche TF-IDF\n",
    "    tfidf_query = tfidf_vectorizer.transform([query])\n",
    "    similarites_tfidf = tfidf_cosine_similarity(tfidf_query, tfidf_matrix)\n",
    "\n",
    "    # Recherche par mots-clés\n",
    "    scores_keywords = []\n",
    "    for doc in documents:\n",
    "        mots_cles = doc.get('keyword_s', []) + doc.get('extracted_keywords', [])\n",
    "        scores_keywords.append(sum(1 for mot in mots_cles if mot.lower() in query.lower()))\n",
    "    \n",
    "    # Combinaison des scores\n",
    "    # Attention : `similarites_tfidf` est 2D, donc on prend le vecteur [0]\n",
    "    scores_combines = (0.3 * similarites_sémantiques.cpu() + 0.6 * similarites_tfidf[0] + 0.1 * torch.tensor(scores_keywords))\n",
    "\n",
    "    # Tri des résultats par pertinence\n",
    "    indices_tries = scores_combines.argsort(descending=True)  # Indices triés par score\n",
    "    return [documents[i] for i in indices_tries[:10]]\n"
   ],
   "outputs": [],
   "execution_count": 52
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-05T18:02:34.598706Z",
     "start_time": "2025-01-05T18:02:34.579916Z"
    }
   },
   "cell_type": "code",
   "source": "query = \"Give me all documents written by Stéphanie Mailles-Viard Metz\"",
   "outputs": [],
   "execution_count": 80
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-05T18:02:37.909013Z",
     "start_time": "2025-01-05T18:02:36.433537Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ESSAIE D'UNE METHODE EXTRACTION DE MOT CLE DE LA QUERY\n",
    "\n",
    "# Extraction de mots-clés\n",
    "keywords_modele = KeyBERT()\n",
    "keywordsQuery = keywords_modele.extract_keywords(query, keyphrase_ngram_range=(1, 3), top_n=1)\n",
    "\n",
    "print(query)\n",
    "print(keywordsQuery)\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Give me all documents written by Stéphanie Mailles-Viard Metz\n",
      "[('written stéphanie mailles', 0.6481)]\n"
     ]
    }
   ],
   "execution_count": 81
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-05T18:03:04.041594Z",
     "start_time": "2025-01-05T18:03:03.917653Z"
    }
   },
   "source": [
    "# Exemple de requête\n",
    "\n",
    "resultats = recherche_hybride(keywordsQuery[0][0], tfidf_vectorizer, tfidf_matrix, embeddings, documents, modele)\n",
    "\n",
    "# Afficher les résultats\n",
    "for res in resultats:\n",
    "    print(f\"Titre: {res['title_s']}, Mots-clés: {res['keyword_s']}, Auteurs: {res['authFullName_s']}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Titre: ['Synergistic insights: Exploring continuous learning and explainable AI in handwritten digit recognition'], Mots-clés: [''], Auteurs: ['Asma Kharrat', 'Fadoua Drira', 'Franck Lebourgeois', 'Bertrand Kerautret']\n",
      "Titre: ['Synergistic insights: Exploring continuous learning and explainable AI in handwritten digit recognition'], Mots-clés: [''], Auteurs: ['Asma Kharrat', 'Fadoua Drira', 'Franck Lebourgeois', 'Bertrand Kerautret']\n",
      "Titre: ['Les services Web'], Mots-clés: [''], Auteurs: ['Djamal Benslimane']\n",
      "Titre: ['Artificial Intelligence. What is it, exactly?'], Mots-clés: [''], Auteurs: ['Frédéric Alexandre', 'Christian Bessiere', 'Jean-François Bonnefon', 'Tristan Cazenave', 'Raja Chatila', 'Antoine Cornuejols', 'Frédéric Cuppens', 'Sébastien Destercke', 'Béatrice Daille', 'Jérôme Euzenat', 'Jean-Gabriel Ganascia', 'Malik Ghallab', 'Christian Wolf', 'Catherine Pelachaud', 'Nicolas Maudet', 'Matthieu Geist', 'Sébastien Konieczny', 'Frédéric Koriche', 'Jérôme Lang', 'Pierre Marquis', 'Christel Vrain', 'Marie-Christine Rousset', 'Engelbert Mephu-Nguifo', 'Jacques Nicolas', 'Vianney Perchet', 'Philippe Dague', 'Patrick Saint Dizier', 'Frédéric Saubion', 'Christine Solnon', 'Karim Tabia']\n",
      "Titre: ['DRUID : coupling user written documents and databases'], Mots-clés: [''], Auteurs: ['Youakim Badr', 'Frederique Laforest', 'André Flory']\n",
      "Titre: ['Actes du workshop « Apprentissage en Réseau et Auto-régulation » (ApRA 2013)'], Mots-clés: [''], Auteurs: ['Elise Lavoué', 'Stéphanie Mailles-Viard Metz']\n",
      "Titre: ['Actes de l\\'Atelier ApRA \"Apprentissage en Réseau et Auto-régulation'], Mots-clés: [''], Auteurs: ['Elise Lavoué', 'Stéphanie Mailles-Viard Metz']\n",
      "Titre: ['Using interaction traces for evolutionary design support - Application on the Virtual Campus VCIel'], Mots-clés: [''], Auteurs: ['Karim Sehaba', 'Stéphanie Mailles-Viard Metz']\n",
      "Titre: ['AntSolver'], Mots-clés: [''], Auteurs: ['Christine Solnon']\n",
      "Titre: [\"Modèles et outils pour rendre possible la réutilisation informatique de profils d'apprenants hétérogènes\"], Mots-clés: [''], Auteurs: ['Stéphanie Jean-Daubias', 'Carole Eyssautier-Bavay', 'Marie Lefevre']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ncorr\\AppData\\Local\\Temp\\ipykernel_19932\\941934588.py:42: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  scores_combines = (0.3 * similarites_sémantiques.cpu() + 0.6 * similarites_tfidf[0] + 0.1 * torch.tensor(scores_keywords))\n"
     ]
    }
   ],
   "execution_count": 82
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-05T18:00:32.129166Z",
     "start_time": "2025-01-05T18:00:30.529761Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Give me all documents written by Stéphanie Mailles-Viard Metz\n",
      "[('written stéphanie mailles', 0.6481)]\n"
     ]
    }
   ],
   "execution_count": 74
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-05T18:01:43.871717Z",
     "start_time": "2025-01-05T18:01:43.861011Z"
    }
   },
   "source": [
    "#on construit un prompt compréhensible pour le LLM\n",
    "\n",
    "def build_prompt(query,keyWordQuery, results):\n",
    "\n",
    "    prompt = \"You are an AI assistant who answers user questions based on the documents provided in the context. Answer only using the context provided and be as concise as possible about the important information. If you're not sure, just say you don't know how to answer.\\n\\n\"\n",
    "\n",
    "    prompt += f\"User Question : {query}\\n\\n\"\n",
    "\n",
    "    prompt += f\"Keywords extracted from the user query : {keyWordQuery}\\n\\n\"\n",
    "\n",
    "    prompt += \"Relevant articles found :\\n\"\n",
    "    \n",
    "    for i, result in enumerate(results, start=1):\n",
    "        prompt += (\n",
    "            f\"{i}. Title : {result['title_s']}\\n\"\n",
    "            f\"   Abstract : {result['abstract_s']}\\n\"\n",
    "            f\"   Keywords : {', '.join(result['keyword_s'])}\\n\"\n",
    "            f\"   Authors : {', '.join(result['authFullName_s'])}\\n\\n\"\n",
    "        )\n",
    "    return prompt\n",
    "\n",
    "# Crée le prompt\n",
    "print()\n",
    "prompt = build_prompt(query, keywordsQuery[0][0],resultats)\n",
    "print(prompt)  # Vérifie ce que le LLM recevra\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You are an AI assistant who answers user questions based on the documents provided in the context. Answer only using the context provided and be as concise as possible about the important information. If you're not sure, just say you don't know how to answer.\n",
      "\n",
      "User Question : Give me all documents written by Stéphanie Mailles-Viard Metz\n",
      "\n",
      "Keywords extracted from the user query : written stéphanie mailles\n",
      "\n",
      "Relevant articles found :\n",
      "1. Title : ['Modèles de représentation de la sémantique des documents']\n",
      "   Abstract : ['']\n",
      "   Keywords : \n",
      "   Authors : Sylvie Calabretto\n",
      "\n",
      "2. Title : ['Documents à structures multiples']\n",
      "   Abstract : ['']\n",
      "   Keywords : \n",
      "   Authors : Rocio Abascal, Michel Beigbeder, Aurélien Bénel, Sylvie Calabretto, Bertrand Chabbat, Pierre-Antoine Champin, Noureddine Chatti, David Jouve, Yannick Prié, Béatrice Rumpler, Eric Thivant\n",
      "\n",
      "3. Title : ['Actes du workshop « Apprentissage en Réseau et Auto-régulation » (ApRA 2013)']\n",
      "   Abstract : [\"Grâce à l’évolution du Web, les acteurs de l’apprentissage (apprenants, enseignants et concepteurs) ont accès à des plateformes éducatives sociales de plus en plus perfectionnées et complexes. Après la mise en place des Campus et Universités Numériques, le mouvement actuel des MOOCs (“Massive Open Online Courses”) ouvre la voie vers de nouvelles situations d’apprentissage humain, tant dans l’utilisation des outils que dans le positionnement des acteurs. En effet, le savoir est « à la carte ». Les ressources, même si elles sont de grande qualité, sont centralisées sur des plateformes, selon des logiques variées, avec un accompagnement plus ou moins régulier adossé à des outils de communication divers, et avec parfois une certification. L’environnement numérique est dynamique, il ne vit que grâce aux interactions entre les acteurs dans les réseaux qui se constituent formellement ou informellement, mais il est aussi constitué d’outils et de ressources que chacun doit s’approprier en fonction de ses objectifs. Dans cet esprit, l’enseignant peut s’investir beaucoup dans la production de ressources, voire d’un parcours pédagogique, et ne pas intervenir comme accompagnant dans le processus d’apprentissage de l’apprenant. Ainsi, plus que jamais, l’apprenant se doit d’être le principal acteur - volontaire, engagé et autonome – de son apprentissage. Il appartient à plusieurs réseaux sociaux d’apprenants, il doit identifier lui-même ses atouts et faiblesses, ses intérêts, ses motivations. Il conduit et participe donc à des activités (individuelles et collectives) pour lesquelles il n’est pas nécessairement préparé et formé. Une grande passivité, un manque de présence sur les réseaux peut avoir des conséquences importantes sur ses apprentissages. Ce type d’environnements éducatifs suscite tout particulièrement la collaboration et l’entraide entre apprenants afin de maintenir la motivation et de combler le manque de présence physique d’un enseignant ou tuteur pour appréhender les ressources disponibles. La communication et l’apprentissage en réseau ne se font pas naturellement, l’apprenant doit trouver sa place en tant qu’individu au sein de différents collectifs (l’environnement social global et les sous-groupes de travail dans lesquels il est engagé). Pour être efficace, il doit être capable de s’auto-évaluer, analyser ses réflexions, planifier son travail, etc. Il est donc amené à travailler sur ses capacités métacognitives, conduire une pratique réflexive et d’autorégulation. Ce travail individuel peut être supporté par l’utilisation d’environnements personnels d’apprentissage (Personal Learning Environment) qui proposent des espaces et des outils de stockage, de partage, de gestion des tâches ... et permettent de personnaliser son activité. Dans ce contexte d’apprentissage en réseau, se mêlent donc différentes dimensions, les sphères publiques et privées qui interagissent et ont des effets sur la construction de l’identité numérique de l’apprenant. Ce positionnement montre l’intérêt d’une réflexion et d’une interaction entre plusieurs disciplines : des sciences de l’éducation à l’informatique en passant par la psychologie, la sociologie, l’information et la communication, les sciences du langage et les sciences cognitives. L’atelier ApRA («Apprentissage en Réseau et Auto-régulation») a pour objectif de réunir des chercheurs issus de ces différentes disciplines afin de croiser les regards, recenser les recherches sur cette thématique, élaborer des pistes de réflexion pour mettre en place des études pluridisciplinaires (observatoire de pratiques, préconisations dans les conceptions) et enfin initier des projets de recherche et publications. L’appel à communication s’est voulu assez large autour de la thématique de l’atelier, en posant les questions suivantes : – Quels outils pour quelles activités métacognitives et/ou d’auto-régulation en apprentissage en réseau ? – Comment des outils de communication, de partage (blog, e-portfolio, ...), de production (éditeur de textes, tableau blanc, cartes mentales ...), de gestion de la tâche (LMS, PLE, ...) peuvent accompagner (former à) l’auto-régulation (réflexivité, planification, auto-évaluation, auto-efficacité, créativité, ...) ? – Quelle place pour les environnements personnels d’apprentissage (Personal Learning Environments ou PLE) dans ce contexte d’apprentissage en réseau ? Quelle(s) utilité(s) ? – Quelle gestion de l’identité numérique au sein des réseaux d’apprentissage : processus de construction, présentation de soi ? – Quels scénarios pédagogiques pour apprendre à être autonome dans ce contexte ? Nous avons reçu quatre soumissions, qui ont toutes été retenues pour communication et publication dans les actes de l’atelier. Dans leur article, Laurence Gagnière et Gaëlle Molinari proposent un scénario pédagogique, soutenu par l’utilisation d’un eportfolio, pour apprendre à des étudiants engagés dans une formation à distance à développer des compétences réflexives et d’auto-régulation. Elles mettent en perspective l’étude des régulations sociales qui émergent dans de telles situations entre l’apprenant et ses pairs et entre l’apprenant et l’enseignant. Mathieu Loiseau propose une analyse des usages de la section « culture » de Livemocha, une communauté informelle d'apprentissage des langues. A partir de principes de la didactique des langues, l’auteur analyse les traces d’activité pour montrer que les fonctionnalités de la section culture de Livemocha ne fournissent a priori pas un contexte favorisant directement l'acquisition d'une langue. A partir de cette analyse, l’auteur propose de nouvelles fonctionnalités dites « sociales » pour favoriser l’adoption de Livemocha et la participation. Il conclut par la limitation actuelle des plates-formes communautaires : elles ne permettent pas d’accéder aux données de façon formelle, et de faire de l’utilisateur l'objet central de l'analyse plutôt que comme variable des objets observés. L’article de Catherine Loisy présente une étude sur l’utilisation de blogs collaboratifs afin de susciter une démarche réflexive des enseignants sur leurs pratiques pédagogiques et ainsi développer des compétences professionnelles. L’auteur montre comment les enseignants intègrent progressivement le numérique dans leurs pratiques, mettent en place une régulation de leur activité professionnelle, et s’orientent vers une forme de « présence numérique ». Cette étude sera complétée, dans le cadre du projet INO (« Identité numérique et orientation ») par une analyse systématique des liens entre les blogs collaboratifs des enseignants et ceux des élèves, afin d’étudier le développement des compétences numériques des uns et des autres. Enfin, Chrysta Pélissier présente le résultat d’une expérience liée à l’utilisation d’un réseau social numérique dédié à l’éducation, le réseau Beebac d’Unisciel, intégré à un dispositif de formation hybride en cours d’informatique en IUT. L’auteur montre comment ce réseau peut constituer, à travers les fonctionnalités qu’il propose, une aide à l’apprentissage. Nous retenons principalement de cette étude le besoin pour les étudiants de personnalisation de l’environnement, notamment l’annotation personnelle des supports, et la possibilité de les organiser individuellement par exemple à l’aide de carte mentale. Ainsi, les soumissions proviennent de deux disciplines : les sciences du langage et la psychologie. Nous ne pouvons que regretter que des chercheurs d’autres disciplines comme l’informatique, les sciences de l’éducation, ou de l’information et de la communication ne se soient pas emparés de cette thématique. Elles seront néanmoins représentées par les membres du comité scientifique, issus de diverses disciplines, qui seront appelés à discuter lors de la table ronde de l’atelier. Du fait notamment de l’absence de contribution en informatique, les environnements proposés ne sont pas nouveaux, mais les pratiques mises en place autour de ces environnements sont en évolution vers une autonomisation des apprenants et enseignants à partir d’une démarche réflexive et d’auto-régulation. Le regard critique porté sur les environnements existants promet des débats intéressants lors de l’atelier et l’émergence d’idées pour la conception de nouveaux environnements support à l’apprentissage en réseau.\"]\n",
      "   Keywords : \n",
      "   Authors : Elise Lavoué, Stéphanie Mailles-Viard Metz\n",
      "\n",
      "4. Title : ['Actes de l\\'Atelier ApRA \"Apprentissage en Réseau et Auto-régulation']\n",
      "   Abstract : ['']\n",
      "   Keywords : \n",
      "   Authors : Elise Lavoué, Stéphanie Mailles-Viard Metz\n",
      "\n",
      "5. Title : ['Document Analysis Systems']\n",
      "   Abstract : ['']\n",
      "   Keywords : \n",
      "   Authors : Seiichi Uchida, Elisa H. Barney Smith, Véronique Eglin\n",
      "\n",
      "6. Title : ['Synergistic insights: Exploring continuous learning and explainable AI in handwritten digit recognition']\n",
      "   Abstract : ['']\n",
      "   Keywords : \n",
      "   Authors : Asma Kharrat, Fadoua Drira, Franck Lebourgeois, Bertrand Kerautret\n",
      "\n",
      "7. Title : ['Synergistic insights: Exploring continuous learning and explainable AI in handwritten digit recognition']\n",
      "   Abstract : ['']\n",
      "   Keywords : \n",
      "   Authors : Asma Kharrat, Fadoua Drira, Franck Lebourgeois, Bertrand Kerautret\n",
      "\n",
      "8. Title : ['Using interaction traces for evolutionary design support - Application on the Virtual Campus VCIel']\n",
      "   Abstract : ['This article addresses evolutionary design in the context of e-learning devices. It proposes a design approach that takes into account the changing behaviours and needs of different actors (tutors, authors and learners) in order to evolve and adapt a training device to real practices. For this, our approach is to consider traces of interaction as knowledge sources that the designer can exploit in the design process. The principle technique of our proposal is to observe the quantitative and qualitative actions of actors on the learning platform and to represent them in modelled traces, to transform these traces in order to extract high level information on the actors activities, and finally, to propose visualisation tools of this information. We have applied our work in virtual campus VCIEL, where data for this study were obtained via participation of 2 designers, 13 tutors and 68 students from four classes that have been trained since 2006.']\n",
      "   Keywords : \n",
      "   Authors : Karim Sehaba, Stéphanie Mailles-Viard Metz\n",
      "\n",
      "9. Title : ['Les services Web']\n",
      "   Abstract : ['']\n",
      "   Keywords : \n",
      "   Authors : Djamal Benslimane\n",
      "\n",
      "10. Title : ['Artificial Intelligence. What is it, exactly?']\n",
      "   Abstract : ['This book is for all those who are curious to learn what artificial intelligence (AI) is. It aims at covering artificial intelligence in all its aspects and all its diversity, without bias. It is a purposely brief introduction to the subject, that has been kept as elementary as possible for a broader audience. It has been written by researchers in the field, on the initiative of the GDR IA, a research group of the French National Center for Scientific Research (CNRS), dedicated to the formal and algorithmic aspects of AI. This makes it unique in its kind because it aims at covering artificial intelligence in all its aspects and all its diversity. It comprises a brief history of AI and a presentation of its key concepts; it describes the principal areas where AI is at work, the interactions between AI and other scientific disciplines and finally answers questions that are often raised about AI. It ends with a glossary of technical terms used and a selected list of references. This book has been translated into English by Rosemary Patricot and Philippe Dague This makes it unique in its kind because it aims at covering artificial intelligence in all its aspects and all its diversity.']\n",
      "   Keywords : \n",
      "   Authors : Frédéric Alexandre, Christian Bessiere, Jean-François Bonnefon, Tristan Cazenave, Raja Chatila, Antoine Cornuejols, Frédéric Cuppens, Sébastien Destercke, Béatrice Daille, Jérôme Euzenat, Jean-Gabriel Ganascia, Malik Ghallab, Christian Wolf, Catherine Pelachaud, Nicolas Maudet, Matthieu Geist, Sébastien Konieczny, Frédéric Koriche, Jérôme Lang, Pierre Marquis, Christel Vrain, Marie-Christine Rousset, Engelbert Mephu-Nguifo, Jacques Nicolas, Vianney Perchet, Philippe Dague, Patrick Saint Dizier, Frédéric Saubion, Christine Solnon, Karim Tabia\n",
      "\n",
      "\n"
     ]
    }
   ],
   "execution_count": 79
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-05T17:05:56.191893Z",
     "start_time": "2025-01-05T17:05:56.179259Z"
    }
   },
   "source": [
    "#test CUDA\n",
    "def get_gpu_info():\n",
    "    if torch.cuda.is_available():\n",
    "        current_device = torch.cuda.current_device()\n",
    "        print(f\"CUDA est disponible. Utilisation du GPU: {torch.cuda.get_device_name(current_device)}\")\n",
    "        print(f\"Nombre de GPUs disponibles : {torch.cuda.device_count()}\")\n",
    "        print(f\"Mémoire GPU totale: {torch.cuda.get_device_properties(current_device).total_memory / 1024**3:.2f} GB\")\n",
    "        print(f\"Mémoire GPU allouée: {torch.cuda.memory_allocated(current_device) / 1024**3:.2f} GB\")\n",
    "        print(f\"Mémoire GPU réservée: {torch.cuda.memory_reserved(current_device) / 1024**3:.2f} GB\")\n",
    "    else:\n",
    "        print(\"CUDA n'est pas disponible. PyTorch utilisera le CPU.\")\n",
    "\n",
    "# Set the device to GPU if available\n",
    "\n",
    "get_gpu_info()\n",
    "print(\"-----------------------------\")\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(torch.cuda.get_device_name(torch.device('cuda:0')))\n",
    "print(\"Used Device:\", device)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA est disponible. Utilisation du GPU: NVIDIA GeForce RTX 3060 Laptop GPU\n",
      "Nombre de GPUs disponibles : 1\n",
      "Mémoire GPU totale: 6.00 GB\n",
      "Mémoire GPU allouée: 0.44 GB\n",
      "Mémoire GPU réservée: 2.83 GB\n",
      "-----------------------------\n",
      "NVIDIA GeForce RTX 3060 Laptop GPU\n",
      "Used Device: cuda\n"
     ]
    }
   ],
   "execution_count": 55
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "end_time": "2025-01-05T17:05:56.222699Z",
     "start_time": "2025-01-05T17:05:56.204489Z"
    }
   },
   "source": [
    "# from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "# from huggingface_hub import login\n",
    "#\n",
    "#\n",
    "# # Se connecter à Hugging Face\n",
    "# login(token=\"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\")\n",
    "#\n",
    "# # Charger le modèle\n",
    "# model_name = \"meta-llama/Llama-2-7b-hf\"\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "# model = AutoModelForCausalLM.from_pretrained(model_name, device_map=\"auto\")"
   ],
   "outputs": [],
   "execution_count": 56
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "end_time": "2025-01-05T17:05:56.331285Z",
     "start_time": "2025-01-05T17:05:56.317173Z"
    }
   },
   "source": [
    "# # Préparer l'entrée pour le modèle\n",
    "# inputs = tokenizer(prompt, return_tensors=\"pt\")  # Utilise le GPU si disponible\n",
    "#\n",
    "# # Générer la réponse\n",
    "# outputs = model.generate(\n",
    "#     inputs[\"input_ids\"],\n",
    "#     max_new_tokens=500,  # Longueur maximale de la réponse\n",
    "#     num_return_sequences=1,  # Nombre de réponses générées\n",
    "#     temperature=0.7,  # Contrôle la créativité\n",
    "# )\n",
    "#\n",
    "# # Étape 5 : Décoder la réponse\n",
    "# response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "# print(response)"
   ],
   "outputs": [],
   "execution_count": 57
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-05T17:05:56.409279Z",
     "start_time": "2025-01-05T17:05:56.395524Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def formatte_documents(documents):\n",
    "    doc_format = []\n",
    "    for doc in documents:\n",
    "        titre = \" | \".join(doc.get(\"title_s\", []))\n",
    "        abstract = \" \".join(doc.get(\"abstract_s\", []))\n",
    "        mots_cles = \", \".join(doc.get(\"keywords_s\", []) + doc.get(\"extracted_keywords\", []))\n",
    "        auteurs = \", \".join(doc.get(\"authors_s\", []))\n",
    "        date = \" | \".join(doc.get(\"date_s\", []))\n",
    "\n",
    "        texte = f\"Titre: {titre}\\nAbstract: {abstract}\\Mots-clés: {mots_cles}\\Auteurs: {auteurs}\\Date: {date}\"\n",
    "        doc_format.append(texte)\n",
    "    return doc_format"
   ],
   "outputs": [],
   "execution_count": 58
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-05T17:19:38.989990Z",
     "start_time": "2025-01-05T17:14:32.029438Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import ollama\n",
    "\n",
    "response = ollama.chat(\n",
    "    model=\"mistral\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": prompt\n",
    "            # + \"\\n\".join(documents_formattes[item[1]] for item in most_similar_chunks),\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": prompt},\n",
    "    ],\n",
    ")\n",
    "print(\"\\n\\n\")\n",
    "print(response[\"message\"][\"content\"])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "1. Title: ['Actes de l'Atelier ApRA \"Apprentissage en Réseau et Auto-régulation']\n",
      "     Abstract: ['These proceedings present the papers and discussions from the ApRA workshop \"Learning in Network and Self-regulation\". The event aimed to bring together researchers from various fields to share their work on learning in networks, self-regulated learning, and related topics. The articles cover a wide range of topics, including networked learning, self-assessment, adaptive educational systems, and the use of technology in education.']\n",
      "     Keywords: ['learning in networks', 'self-regulation', 'education', 'networked learning', 'adaptive educational systems']\n",
      "     Authors: Elise Lavoué, Stéphanie Mailles-Viard Metz\n",
      "\n",
      "  2. Title: ['Document Analysis Systems']\n",
      "     Abstract: ['This article discusses the development and implementation of document analysis systems. It provides an overview of various techniques used in the field, such as optical character recognition (OCR), natural language processing (NLP), and information extraction. The authors also present a case study on the use of document analysis systems in the medical domain.']\n",
      "     Keywords: ['document analysis', 'optical character recognition (OCR)', 'natural language processing (NLP)', 'information extraction']\n",
      "     Authors: Seiichi Uchida, Elisa H. Barney Smith, Véronique Eglin\n",
      "\n",
      "  3. Title: ['Synergistic insights: Exploring continuous learning and explainable AI in handwritten digit recognition']\n",
      "     Abstract: ['This paper explores the potential synergy between continuous learning and explainable AI (XAI) in the context of handwritten digit recognition. The authors propose a novel approach that combines both techniques to improve the accuracy and interpretability of the models. They also discuss the challenges and opportunities of this approach, as well as its implications for real-world applications.']\n",
      "     Keywords: ['handwritten digit recognition', 'continuous learning', 'explainable AI (XAI)', 'synergy']\n",
      "     Authors: Asma Kharrat, Fadoua Drira, Franck Lebourgeois, Bertrand Kerautret\n",
      "\n",
      "  4. Title: ['Synergistic insights: Exploring continuous learning and explainable AI in handwritten digit recognition']\n",
      "     Abstract: ['This paper explores the potential synergy between continuous learning and explainable AI (XAI) in the context of handwritten digit recognition. The authors propose a novel approach that combines both techniques to improve the accuracy and interpretability of the models. They also discuss the challenges and opportunities of this approach, as well as its implications for real-world applications.']\n",
      "     Keywords: ['handwritten digit recognition', 'continuous learning', 'explainable AI (XAI)', 'synergy']\n",
      "     Authors: Asma Kharrat, Fadoua Drira, Franck Lebourgeois, Bertrand Kerautret\n",
      "\n",
      "  5. Title: ['Using interaction traces for evolutionary design support - Application on the Virtual Campus VCIel']\n",
      "     Abstract: ['This article proposes a design approach that takes into account the changing behaviors and needs of different actors (tutors, authors, and learners) in order to evolve and adapt a training device to real practices. The approach uses interaction traces as knowledge sources for designers to exploit during the design process. The proposed technique observes quantitative and qualitative actions of actors on the learning platform, transforms these traces into modelled traces, extracts high-level information from the actor's activity, and provides visualization tools of this information. This work has been applied in the virtual campus VCIEL, where data for this study were obtained via participation of 2 designers, 13 tutors, and 68 students from four classes that have been trained since 2006.']\n",
      "     Keywords: ['evolutionary design', 'interaction traces', 'learning platform', 'visualization tools']\n",
      "     Authors: Karim Sehaba, Stéphanie Mailles-Viard Metz\n",
      "\n",
      "  6. Title: ['Les services Web']\n",
      "     Abstract: ['This article discusses web services and their various applications. It provides an overview of the technologies used to create and deploy web services, as well as the benefits and challenges associated with using them. The authors also present a case study on the use of web services in the financial sector.']\n",
      "     Keywords: ['web services', 'technologies', 'financial sector']\n",
      "     Authors: Djamal Benslimane\n",
      "\n",
      "  7. Title: ['Artificial Intelligence. What is it, exactly?']\n",
      "     Abstract: ['This book provides an introduction to artificial intelligence (AI) and its various applications. It discusses the history, principles, techniques, and challenges associated with AI, as well as its impact on society and the economy. The authors also provide examples of real-world AI systems and their potential benefits and limitations.']\n",
      "     Keywords: ['artificial intelligence (AI)', 'history', 'principles', 'techniques', 'challenges']\n",
      "     Authors: [Not provided]\n"
     ]
    }
   ],
   "execution_count": 61
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
