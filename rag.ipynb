{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-02T17:05:33.540564Z",
     "start_time": "2025-01-02T17:05:33.521780Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from keybert import KeyBERT\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity as tfidf_cosine_similarity\n",
    "from torch.nn.functional import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-02T17:05:35.638178Z",
     "start_time": "2025-01-02T17:05:35.620617Z"
    }
   },
   "outputs": [],
   "source": [
    "# A EXECUTER LORSQUE LES KEYWORD N'ONT JAMAIS ETE EXTRAITS\n",
    "# Récupère les documents du json\n",
    "# \n",
    "\n",
    "\n",
    "\n",
    "# documents = []\n",
    "# with open(\"./data/documents.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "#     documents = json.load(f)\n",
    "# \n",
    "# # Extraction de mots-clés\n",
    "# keywords_modele = KeyBERT()\n",
    "# \n",
    "# for doc in documents:\n",
    "#     texte = f\"{doc.get('title_s', '')} {doc.get('abstract_s', '')}\"\n",
    "#     keywords = keywords_modele.extract_keywords(texte, keyphrase_ngram_range=(1, 3), top_n=5) \n",
    "#     doc['extracted_keywords'] = [kw[0] for kw in keywords]  # Ajouter les mots-clés\n",
    "\n",
    "# #Une fois les doc changé on les sauvegarde pour pas avoir a reexcuters les cellules\n",
    "# with open(\"./data/documentsExtractedKey.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "#     json.dump(documents, f, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'title_s': ['Fractal inverse problem: an analytical approach'], 'abstract_s': ['Fractal inverse problem: The fractal inverse problem is an important research area with a great number of potential application fields. It constists in finding a fractal model or code that generates a given object. This concept has been introduced by Barnsley with the well known collage theorem [Bar88]. When the considered object is an image, we often speak about fractal image compression. A method has been proposed by Jacquin to solve this kind of inverse problem [Jac92].'], 'authFullName_s': ['Eric Guérin', 'Eric Tosan'], 'producedDateY_i': 2004, 'keyword_s': [''], 'extracted_keywords': ['fractal inverse problem', 'inverse problem fractal', 'approach fractal inverse', 'fractal inverse', 'problem fractal inverse']}\n"
     ]
    }
   ],
   "source": [
    "# A EXECUTER LORSQUE \"./data/documentsExtractedKey.json\" EXISTE DEJA\n",
    "# Récupère les documents du json\n",
    "\n",
    "documents = []\n",
    "with open(\"./data/documentsExtractedKey.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    documents = json.load(f)\n",
    "    \n",
    "# Afficher un exemple de document\n",
    "print(documents[0])\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-02T17:05:38.783044Z",
     "start_time": "2025-01-02T17:05:38.339265Z"
    }
   },
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-02T17:05:45.904650Z",
     "start_time": "2025-01-02T17:05:42.844199Z"
    }
   },
   "outputs": [],
   "source": [
    "# Chargement du modèle\n",
    "modele = SentenceTransformer('multi-qa-mpnet-base-dot-v1')\n",
    "\n",
    "# Extraction des informations des documents\n",
    "informations = [\n",
    "    f\"{doc.get('title_s', '')} \"  # Titre\n",
    "    f\"{', '.join(doc.get('keyword_s', []))} \"  # Mots-clés\n",
    "    f\"{', '.join(doc.get('extracted_keywords', []))} \"  # Mots-clés extraits\n",
    "    f\"Auteurs: {', '.join(doc.get('authFullName_s', []))} \"  # Auteurs\n",
    "    for doc in documents\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-02T17:06:23.013253Z",
     "start_time": "2025-01-02T17:05:48.054227Z"
    }
   },
   "outputs": [],
   "source": [
    "# Générer les embeddings\n",
    "embeddings = modele.encode(informations, convert_to_tensor=True)\n",
    "\n",
    "# Associer chaque embedding à son document\n",
    "documents_valides = [doc for doc, titre in zip(documents, informations) if titre.strip()]\n",
    "documents_embeddings = [\n",
    "    {\"document\": doc, \"embedding\": embedding}\n",
    "    for doc, embedding in zip(documents_valides, embeddings)\n",
    "]\n",
    "\n",
    "# Calculer la similarité cosinus entre les embeddings\n",
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 3))\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(informations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-02T16:25:06.529558Z",
     "start_time": "2025-01-02T16:25:06.515745Z"
    }
   },
   "outputs": [],
   "source": [
    "# Fonction qui cherche les documents les plus pertinents pour une requête\n",
    "def recherche(query, tfidf_vectorizer, tfidf_matrix, embeddings, documents, model):\n",
    "    # Si la requête contient des mots-clés, on effectue une recherche par mots-clés\n",
    "    if detecter_recherche_par_mots_cles(query):\n",
    "        return [res[0] for res in recherche_par_mots_cles(query, documents)]\n",
    "    else:\n",
    "        return recherche_hybride(query, tfidf_vectorizer, tfidf_matrix, embeddings, documents, model)\n",
    "\n",
    "# Fonction qui permet de détecter si la requête est une recherche par mots-clés\n",
    "def detecter_recherche_par_mots_cles(query):\n",
    "    termes_indicateurs = [\"liés à\", \"documents sur\", \"articles sur\", \"mots-clés\", \"thème\", \"traitent de\", \"traitant de\", \"concernant\", \"par rapport à\"]\n",
    "    return any(terme in query.lower() for terme in termes_indicateurs)\n",
    "\n",
    "# Fonction qui recherche les documents par mots-clés\n",
    "def recherche_par_mots_cles(query, documents):\n",
    "    resultats = []\n",
    "    for doc in documents:\n",
    "        mots_cles = doc.get('keyword_s', []) + doc.get('extracted_keywords', []) # On se concentre sur tous les mots-clés\n",
    "        similarite = sum(1 for mot in mots_cles if mot.lower() in query.lower())\n",
    "        if similarite > 0:\n",
    "            resultats.append((doc, similarite))\n",
    "    return sorted(resultats, key=lambda x: x[1], reverse=True)[:10]  # Trier par pertinence\n",
    "\n",
    "# Fonction qui recherche les documents avec une combinaison de similarité sémantique et TF-IDF\n",
    "def recherche_hybride(query, tfidf_vectorizer, tfidf_matrix, embeddings, documents, model):\n",
    "    # Recherche sémantique avec embeddings\n",
    "    query_embedding = model.encode(query, convert_to_tensor=True)\n",
    "    similarites_sémantiques = cosine_similarity(query_embedding, embeddings)\n",
    "    \n",
    "    # Recherche TF-IDF\n",
    "    tfidf_query = tfidf_vectorizer.transform([query])\n",
    "    similarites_tfidf = tfidf_cosine_similarity(tfidf_query, tfidf_matrix)\n",
    "\n",
    "    # Recherche par mots-clés\n",
    "    scores_keywords = []\n",
    "    for doc in documents:\n",
    "        mots_cles = doc.get('keyword_s', []) + doc.get('extracted_keywords', [])\n",
    "        scores_keywords.append(sum(1 for mot in mots_cles if mot.lower() in query.lower()))\n",
    "    \n",
    "    # Combinaison des scores\n",
    "    # Attention : `similarites_tfidf` est 2D, donc on prend le vecteur [0]\n",
    "    scores_combines = (0.3 * similarites_sémantiques.cpu() + 0.6 * similarites_tfidf[0] + 0.1 * torch.tensor(scores_keywords))\n",
    "\n",
    "    # Tri des résultats par pertinence\n",
    "    indices_tries = scores_combines.argsort(descending=True)  # Indices triés par score\n",
    "    return [documents[i] for i in indices_tries[:10]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-02T16:25:06.684050Z",
     "start_time": "2025-01-02T16:25:06.532077Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Titre: ['Modèles de représentation de la sémantique des documents'], Mots-clés: [''], Auteurs: ['Sylvie Calabretto']\n",
      "Titre: ['Actes du workshop « Apprentissage en Réseau et Auto-régulation » (ApRA 2013)'], Mots-clés: [''], Auteurs: ['Elise Lavoué', 'Stéphanie Mailles-Viard Metz']\n",
      "Titre: ['Documents à structures multiples'], Mots-clés: [''], Auteurs: ['Rocio Abascal', 'Michel Beigbeder', 'Aurélien Bénel', 'Sylvie Calabretto', 'Bertrand Chabbat', 'Pierre-Antoine Champin', 'Noureddine Chatti', 'David Jouve', 'Yannick Prié', 'Béatrice Rumpler', 'Eric Thivant']\n",
      "Titre: ['Actes de l\\'Atelier ApRA \"Apprentissage en Réseau et Auto-régulation'], Mots-clés: [''], Auteurs: ['Elise Lavoué', 'Stéphanie Mailles-Viard Metz']\n",
      "Titre: ['Les services Web'], Mots-clés: [''], Auteurs: ['Djamal Benslimane']\n",
      "Titre: ['Un système de mise en relation Image/Transcription pour les documents manuscrits'], Mots-clés: [''], Auteurs: ['Vincent Malleron', 'Véronique Eglin', 'Stéphanie Dord-Crouslé', 'Hubert Emptoz', 'Philippe Régnier']\n",
      "Titre: ['Document Analysis Systems'], Mots-clés: [''], Auteurs: ['Seiichi Uchida', 'Elisa H. Barney Smith', 'Véronique Eglin']\n",
      "Titre: ['Using interaction traces for evolutionary design support - Application on the Virtual Campus VCIel'], Mots-clés: [''], Auteurs: ['Karim Sehaba', 'Stéphanie Mailles-Viard Metz']\n",
      "Titre: ['Synergistic insights: Exploring continuous learning and explainable AI in handwritten digit recognition'], Mots-clés: [''], Auteurs: ['Asma Kharrat', 'Fadoua Drira', 'Franck Lebourgeois', 'Bertrand Kerautret']\n",
      "Titre: ['Synergistic insights: Exploring continuous learning and explainable AI in handwritten digit recognition'], Mots-clés: [''], Auteurs: ['Asma Kharrat', 'Fadoua Drira', 'Franck Lebourgeois', 'Bertrand Kerautret']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ncorr\\AppData\\Local\\Temp\\ipykernel_22552\\941934588.py:42: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  scores_combines = (0.3 * similarites_sémantiques.cpu() + 0.6 * similarites_tfidf[0] + 0.1 * torch.tensor(scores_keywords))\n"
     ]
    }
   ],
   "source": [
    "# Exemple de requête\n",
    "query = \"Donne moi les documents écrit par Stéphanie Mailles-Viard Metz\"\n",
    "resultats = recherche_hybride(query, tfidf_vectorizer, tfidf_matrix, embeddings, documents, modele)\n",
    "\n",
    "# Afficher les résultats\n",
    "for res in resultats:\n",
    "    print(f\"Titre: {res['title_s']}, Mots-clés: {res['keyword_s']}, Auteurs: {res['authFullName_s']}\")"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question utilisateur : Donne moi les documents écrit par Stéphanie Mailles-Viard Metz\n",
      "\n",
      "Articles pertinents trouvés :\n",
      "1. Titre : ['Modèles de représentation de la sémantique des documents']\n",
      "   Abstract : ['']\n",
      "   Keywords : \n",
      "   Auteurs : Sylvie Calabretto\n",
      "\n",
      "2. Titre : ['Actes du workshop « Apprentissage en Réseau et Auto-régulation » (ApRA 2013)']\n",
      "   Abstract : [\"Grâce à l’évolution du Web, les acteurs de l’apprentissage (apprenants, enseignants et concepteurs) ont accès à des plateformes éducatives sociales de plus en plus perfectionnées et complexes. Après la mise en place des Campus et Universités Numériques, le mouvement actuel des MOOCs (“Massive Open Online Courses”) ouvre la voie vers de nouvelles situations d’apprentissage humain, tant dans l’utilisation des outils que dans le positionnement des acteurs. En effet, le savoir est « à la carte ». Les ressources, même si elles sont de grande qualité, sont centralisées sur des plateformes, selon des logiques variées, avec un accompagnement plus ou moins régulier adossé à des outils de communication divers, et avec parfois une certification. L’environnement numérique est dynamique, il ne vit que grâce aux interactions entre les acteurs dans les réseaux qui se constituent formellement ou informellement, mais il est aussi constitué d’outils et de ressources que chacun doit s’approprier en fonction de ses objectifs. Dans cet esprit, l’enseignant peut s’investir beaucoup dans la production de ressources, voire d’un parcours pédagogique, et ne pas intervenir comme accompagnant dans le processus d’apprentissage de l’apprenant. Ainsi, plus que jamais, l’apprenant se doit d’être le principal acteur - volontaire, engagé et autonome – de son apprentissage. Il appartient à plusieurs réseaux sociaux d’apprenants, il doit identifier lui-même ses atouts et faiblesses, ses intérêts, ses motivations. Il conduit et participe donc à des activités (individuelles et collectives) pour lesquelles il n’est pas nécessairement préparé et formé. Une grande passivité, un manque de présence sur les réseaux peut avoir des conséquences importantes sur ses apprentissages. Ce type d’environnements éducatifs suscite tout particulièrement la collaboration et l’entraide entre apprenants afin de maintenir la motivation et de combler le manque de présence physique d’un enseignant ou tuteur pour appréhender les ressources disponibles. La communication et l’apprentissage en réseau ne se font pas naturellement, l’apprenant doit trouver sa place en tant qu’individu au sein de différents collectifs (l’environnement social global et les sous-groupes de travail dans lesquels il est engagé). Pour être efficace, il doit être capable de s’auto-évaluer, analyser ses réflexions, planifier son travail, etc. Il est donc amené à travailler sur ses capacités métacognitives, conduire une pratique réflexive et d’autorégulation. Ce travail individuel peut être supporté par l’utilisation d’environnements personnels d’apprentissage (Personal Learning Environment) qui proposent des espaces et des outils de stockage, de partage, de gestion des tâches ... et permettent de personnaliser son activité. Dans ce contexte d’apprentissage en réseau, se mêlent donc différentes dimensions, les sphères publiques et privées qui interagissent et ont des effets sur la construction de l’identité numérique de l’apprenant. Ce positionnement montre l’intérêt d’une réflexion et d’une interaction entre plusieurs disciplines : des sciences de l’éducation à l’informatique en passant par la psychologie, la sociologie, l’information et la communication, les sciences du langage et les sciences cognitives. L’atelier ApRA («Apprentissage en Réseau et Auto-régulation») a pour objectif de réunir des chercheurs issus de ces différentes disciplines afin de croiser les regards, recenser les recherches sur cette thématique, élaborer des pistes de réflexion pour mettre en place des études pluridisciplinaires (observatoire de pratiques, préconisations dans les conceptions) et enfin initier des projets de recherche et publications. L’appel à communication s’est voulu assez large autour de la thématique de l’atelier, en posant les questions suivantes : – Quels outils pour quelles activités métacognitives et/ou d’auto-régulation en apprentissage en réseau ? – Comment des outils de communication, de partage (blog, e-portfolio, ...), de production (éditeur de textes, tableau blanc, cartes mentales ...), de gestion de la tâche (LMS, PLE, ...) peuvent accompagner (former à) l’auto-régulation (réflexivité, planification, auto-évaluation, auto-efficacité, créativité, ...) ? – Quelle place pour les environnements personnels d’apprentissage (Personal Learning Environments ou PLE) dans ce contexte d’apprentissage en réseau ? Quelle(s) utilité(s) ? – Quelle gestion de l’identité numérique au sein des réseaux d’apprentissage : processus de construction, présentation de soi ? – Quels scénarios pédagogiques pour apprendre à être autonome dans ce contexte ? Nous avons reçu quatre soumissions, qui ont toutes été retenues pour communication et publication dans les actes de l’atelier. Dans leur article, Laurence Gagnière et Gaëlle Molinari proposent un scénario pédagogique, soutenu par l’utilisation d’un eportfolio, pour apprendre à des étudiants engagés dans une formation à distance à développer des compétences réflexives et d’auto-régulation. Elles mettent en perspective l’étude des régulations sociales qui émergent dans de telles situations entre l’apprenant et ses pairs et entre l’apprenant et l’enseignant. Mathieu Loiseau propose une analyse des usages de la section « culture » de Livemocha, une communauté informelle d'apprentissage des langues. A partir de principes de la didactique des langues, l’auteur analyse les traces d’activité pour montrer que les fonctionnalités de la section culture de Livemocha ne fournissent a priori pas un contexte favorisant directement l'acquisition d'une langue. A partir de cette analyse, l’auteur propose de nouvelles fonctionnalités dites « sociales » pour favoriser l’adoption de Livemocha et la participation. Il conclut par la limitation actuelle des plates-formes communautaires : elles ne permettent pas d’accéder aux données de façon formelle, et de faire de l’utilisateur l'objet central de l'analyse plutôt que comme variable des objets observés. L’article de Catherine Loisy présente une étude sur l’utilisation de blogs collaboratifs afin de susciter une démarche réflexive des enseignants sur leurs pratiques pédagogiques et ainsi développer des compétences professionnelles. L’auteur montre comment les enseignants intègrent progressivement le numérique dans leurs pratiques, mettent en place une régulation de leur activité professionnelle, et s’orientent vers une forme de « présence numérique ». Cette étude sera complétée, dans le cadre du projet INO (« Identité numérique et orientation ») par une analyse systématique des liens entre les blogs collaboratifs des enseignants et ceux des élèves, afin d’étudier le développement des compétences numériques des uns et des autres. Enfin, Chrysta Pélissier présente le résultat d’une expérience liée à l’utilisation d’un réseau social numérique dédié à l’éducation, le réseau Beebac d’Unisciel, intégré à un dispositif de formation hybride en cours d’informatique en IUT. L’auteur montre comment ce réseau peut constituer, à travers les fonctionnalités qu’il propose, une aide à l’apprentissage. Nous retenons principalement de cette étude le besoin pour les étudiants de personnalisation de l’environnement, notamment l’annotation personnelle des supports, et la possibilité de les organiser individuellement par exemple à l’aide de carte mentale. Ainsi, les soumissions proviennent de deux disciplines : les sciences du langage et la psychologie. Nous ne pouvons que regretter que des chercheurs d’autres disciplines comme l’informatique, les sciences de l’éducation, ou de l’information et de la communication ne se soient pas emparés de cette thématique. Elles seront néanmoins représentées par les membres du comité scientifique, issus de diverses disciplines, qui seront appelés à discuter lors de la table ronde de l’atelier. Du fait notamment de l’absence de contribution en informatique, les environnements proposés ne sont pas nouveaux, mais les pratiques mises en place autour de ces environnements sont en évolution vers une autonomisation des apprenants et enseignants à partir d’une démarche réflexive et d’auto-régulation. Le regard critique porté sur les environnements existants promet des débats intéressants lors de l’atelier et l’émergence d’idées pour la conception de nouveaux environnements support à l’apprentissage en réseau.\"]\n",
      "   Keywords : \n",
      "   Auteurs : Elise Lavoué, Stéphanie Mailles-Viard Metz\n",
      "\n",
      "3. Titre : ['Documents à structures multiples']\n",
      "   Abstract : ['']\n",
      "   Keywords : \n",
      "   Auteurs : Rocio Abascal, Michel Beigbeder, Aurélien Bénel, Sylvie Calabretto, Bertrand Chabbat, Pierre-Antoine Champin, Noureddine Chatti, David Jouve, Yannick Prié, Béatrice Rumpler, Eric Thivant\n",
      "\n",
      "4. Titre : ['Actes de l\\'Atelier ApRA \"Apprentissage en Réseau et Auto-régulation']\n",
      "   Abstract : ['']\n",
      "   Keywords : \n",
      "   Auteurs : Elise Lavoué, Stéphanie Mailles-Viard Metz\n",
      "\n",
      "5. Titre : ['Les services Web']\n",
      "   Abstract : ['']\n",
      "   Keywords : \n",
      "   Auteurs : Djamal Benslimane\n",
      "\n",
      "6. Titre : ['Un système de mise en relation Image/Transcription pour les documents manuscrits']\n",
      "   Abstract : ['Dans cet article nous proposons la description d’un système complet pour l’aide à l’encodage des projets d’éditions électroniques. Notre système réalise l’extraction de la structure des documents manuscrits et propose un encodage des transcriptions prenant en compte les éléments structurels de la page (lignes, paragraphes, fragments). Cette approche permet de réduire considérablement le temps nécessaire à l’encodage d’un corpus et donc de multiplier les éléments indexés. Il permet également d’envisager des applications de navigation et des interfaces utilisateur novatrices.']\n",
      "   Keywords : \n",
      "   Auteurs : Vincent Malleron, Véronique Eglin, Stéphanie Dord-Crouslé, Hubert Emptoz, Philippe Régnier\n",
      "\n",
      "7. Titre : ['Document Analysis Systems']\n",
      "   Abstract : ['']\n",
      "   Keywords : \n",
      "   Auteurs : Seiichi Uchida, Elisa H. Barney Smith, Véronique Eglin\n",
      "\n",
      "8. Titre : ['Using interaction traces for evolutionary design support - Application on the Virtual Campus VCIel']\n",
      "   Abstract : ['This article addresses evolutionary design in the context of e-learning devices. It proposes a design approach that takes into account the changing behaviours and needs of different actors (tutors, authors and learners) in order to evolve and adapt a training device to real practices. For this, our approach is to consider traces of interaction as knowledge sources that the designer can exploit in the design process. The principle technique of our proposal is to observe the quantitative and qualitative actions of actors on the learning platform and to represent them in modelled traces, to transform these traces in order to extract high level information on the actors activities, and finally, to propose visualisation tools of this information. We have applied our work in virtual campus VCIEL, where data for this study were obtained via participation of 2 designers, 13 tutors and 68 students from four classes that have been trained since 2006.']\n",
      "   Keywords : \n",
      "   Auteurs : Karim Sehaba, Stéphanie Mailles-Viard Metz\n",
      "\n",
      "9. Titre : ['Synergistic insights: Exploring continuous learning and explainable AI in handwritten digit recognition']\n",
      "   Abstract : ['']\n",
      "   Keywords : \n",
      "   Auteurs : Asma Kharrat, Fadoua Drira, Franck Lebourgeois, Bertrand Kerautret\n",
      "\n",
      "10. Titre : ['Synergistic insights: Exploring continuous learning and explainable AI in handwritten digit recognition']\n",
      "   Abstract : ['']\n",
      "   Keywords : \n",
      "   Auteurs : Asma Kharrat, Fadoua Drira, Franck Lebourgeois, Bertrand Kerautret\n",
      "\n",
      "\n",
      "Génère une réponse claire et concise basée sur ces articles. Mets en avant les informations clés dans ta réponse.\n"
     ]
    }
   ],
   "source": [
    "#on construit un prompt compréhensible pour le LLM\n",
    "\n",
    "def build_prompt(query, results):\n",
    "    prompt = f\"Question utilisateur : {query}\\n\\n\"\n",
    "    prompt += \"Articles pertinents trouvés :\\n\"\n",
    "    \n",
    "    for i, result in enumerate(results, start=1):\n",
    "        prompt += (\n",
    "            f\"{i}. Titre : {result['title_s']}\\n\"\n",
    "            f\"   Abstract : {result['abstract_s']}\\n\"\n",
    "            f\"   Keywords : {', '.join(result['keyword_s'])}\\n\"\n",
    "            f\"   Auteurs : {', '.join(result['authFullName_s'])}\\n\\n\"\n",
    "        )\n",
    "    prompt += \"\\nGénère une réponse claire et concise basée sur ces articles. Mets en avant les informations clés dans ta réponse.\"\n",
    "    return prompt\n",
    "\n",
    "# Crée le prompt\n",
    "prompt = build_prompt(query, resultats)\n",
    "print(prompt)  # Vérifie ce que le LLM recevra\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-02T16:25:06.699558Z",
     "start_time": "2025-01-02T16:25:06.686055Z"
    }
   },
   "execution_count": 46
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA est disponible. Utilisation du GPU: NVIDIA GeForce RTX 3060 Laptop GPU\n",
      "Nombre de GPUs disponibles : 1\n",
      "Mémoire GPU totale: 6.00 GB\n",
      "Mémoire GPU allouée: 1.35 GB\n",
      "Mémoire GPU réservée: 2.91 GB\n",
      "-----------------------------\n",
      "NVIDIA GeForce RTX 3060 Laptop GPU\n",
      "Used Device: cuda\n"
     ]
    }
   ],
   "source": [
    "#test CUDA\n",
    "def get_gpu_info():\n",
    "    if torch.cuda.is_available():\n",
    "        current_device = torch.cuda.current_device()\n",
    "        print(f\"CUDA est disponible. Utilisation du GPU: {torch.cuda.get_device_name(current_device)}\")\n",
    "        print(f\"Nombre de GPUs disponibles : {torch.cuda.device_count()}\")\n",
    "        print(f\"Mémoire GPU totale: {torch.cuda.get_device_properties(current_device).total_memory / 1024**3:.2f} GB\")\n",
    "        print(f\"Mémoire GPU allouée: {torch.cuda.memory_allocated(current_device) / 1024**3:.2f} GB\")\n",
    "        print(f\"Mémoire GPU réservée: {torch.cuda.memory_reserved(current_device) / 1024**3:.2f} GB\")\n",
    "    else:\n",
    "        print(\"CUDA n'est pas disponible. PyTorch utilisera le CPU.\")\n",
    "\n",
    "# Set the device to GPU if available\n",
    "\n",
    "get_gpu_info()\n",
    "print(\"-----------------------------\")\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(torch.cuda.get_device_name(torch.device('cuda:0')))\n",
    "print(\"Used Device:\", device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-02T16:25:06.714877Z",
     "start_time": "2025-01-02T16:25:06.703087Z"
    }
   },
   "execution_count": 47
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to C:\\Users\\ncorr\\.cache\\huggingface\\token\n",
      "Login successful\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "Using `low_cpu_mem_usage=True` or a `device_map` requires Accelerate: `pip install 'accelerate>=0.26.0'`",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[48], line 11\u001B[0m\n\u001B[0;32m      9\u001B[0m model_name \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmeta-llama/Llama-2-7b-hf\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     10\u001B[0m tokenizer \u001B[38;5;241m=\u001B[39m AutoTokenizer\u001B[38;5;241m.\u001B[39mfrom_pretrained(model_name)\n\u001B[1;32m---> 11\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mAutoModelForCausalLM\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_pretrained\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice_map\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mauto\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\LLM_proj\\lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:564\u001B[0m, in \u001B[0;36m_BaseAutoModelClass.from_pretrained\u001B[1;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001B[0m\n\u001B[0;32m    562\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mtype\u001B[39m(config) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39m_model_mapping\u001B[38;5;241m.\u001B[39mkeys():\n\u001B[0;32m    563\u001B[0m     model_class \u001B[38;5;241m=\u001B[39m _get_model_class(config, \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39m_model_mapping)\n\u001B[1;32m--> 564\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m model_class\u001B[38;5;241m.\u001B[39mfrom_pretrained(\n\u001B[0;32m    565\u001B[0m         pretrained_model_name_or_path, \u001B[38;5;241m*\u001B[39mmodel_args, config\u001B[38;5;241m=\u001B[39mconfig, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mhub_kwargs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs\n\u001B[0;32m    566\u001B[0m     )\n\u001B[0;32m    567\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    568\u001B[0m     \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUnrecognized configuration class \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mconfig\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m for this kind of AutoModel: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    569\u001B[0m     \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mModel type should be one of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m, \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(c\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mfor\u001B[39;00m\u001B[38;5;250m \u001B[39mc\u001B[38;5;250m \u001B[39m\u001B[38;5;129;01min\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39m_model_mapping\u001B[38;5;241m.\u001B[39mkeys())\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    570\u001B[0m )\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\LLM_proj\\lib\\site-packages\\transformers\\modeling_utils.py:3589\u001B[0m, in \u001B[0;36mPreTrainedModel.from_pretrained\u001B[1;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001B[0m\n\u001B[0;32m   3585\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m   3586\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDeepSpeed Zero-3 is not compatible with `low_cpu_mem_usage=True` or with passing a `device_map`.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   3587\u001B[0m         )\n\u001B[0;32m   3588\u001B[0m     \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_accelerate_available():\n\u001B[1;32m-> 3589\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m(\n\u001B[0;32m   3590\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUsing `low_cpu_mem_usage=True` or a `device_map` requires Accelerate: `pip install \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124maccelerate>=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mACCELERATE_MIN_VERSION\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m`\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   3591\u001B[0m         )\n\u001B[0;32m   3593\u001B[0m \u001B[38;5;66;03m# handling bnb config from kwargs, remove after `load_in_{4/8}bit` deprecation.\u001B[39;00m\n\u001B[0;32m   3594\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m load_in_4bit \u001B[38;5;129;01mor\u001B[39;00m load_in_8bit:\n",
      "\u001B[1;31mImportError\u001B[0m: Using `low_cpu_mem_usage=True` or a `device_map` requires Accelerate: `pip install 'accelerate>=0.26.0'`"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from huggingface_hub import login\n",
    "\n",
    "\n",
    "# Se connecter à Hugging Face\n",
    "login(token=\"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\")\n",
    "\n",
    "# Charger le modèle\n",
    "model_name = \"meta-llama/Llama-2-7b-hf\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, device_map=\"auto\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-02T16:25:07.443554Z",
     "start_time": "2025-01-02T16:25:06.715872Z"
    }
   },
   "execution_count": 48
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Préparer l'entrée pour le modèle\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")  # Utilise le GPU si disponiblet\n",
    "\n",
    "# Générer la réponse\n",
    "outputs = model.generate(\n",
    "    inputs[\"input_ids\"],\n",
    "    max_length=500,  # Longueur maximale de la réponse\n",
    "    num_return_sequences=1,  # Nombre de réponses générées\n",
    "    temperature=0.7,  # Contrôle la créativité\n",
    ")\n",
    "\n",
    "# Étape 5 : Décoder la réponse\n",
    "response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "print(response)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-01-02T16:25:07.445544Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
