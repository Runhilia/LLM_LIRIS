{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from keybert import KeyBERT\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity as tfidf_cosine_similarity\n",
    "from torch.nn.functional import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Récupère les documents du json\n",
    "documents = []\n",
    "with open(\"./data/documents.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    documents = json.load(f)\n",
    "\n",
    "# Extraction de mots-clés\n",
    "keywords_modele = KeyBERT()\n",
    "for doc in documents:\n",
    "    texte = f\"{doc.get('title_s', '')} {doc.get('abstract_s', '')}\"\n",
    "    keywords = keywords_modele.extract_keywords(texte, keyphrase_ngram_range=(1, 3), top_n=5) \n",
    "    doc['extracted_keywords'] = [kw[0] for kw in keywords]  # Ajouter les mots-clés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement du modèle\n",
    "modele = SentenceTransformer('multi-qa-mpnet-base-dot-v1')\n",
    "\n",
    "# Extraction des informations des documents\n",
    "informations = [\n",
    "    f\"{doc.get('title_s', '')} \"  # Titre\n",
    "    f\"{', '.join(doc.get('keyword_s', []))} \"  # Mots-clés\n",
    "    f\"{', '.join(doc.get('extracted_keywords', []))} \"  # Mots-clés extraits\n",
    "    f\"Auteurs: {', '.join(doc.get('authFullName_s', []))} \"  # Auteurs\n",
    "    for doc in documents\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Générer les embeddings\n",
    "embeddings = modele.encode(informations, convert_to_tensor=True)\n",
    "\n",
    "# Associer chaque embedding à son document\n",
    "documents_valides = [doc for doc, titre in zip(documents, informations) if titre.strip()]\n",
    "documents_embeddings = [\n",
    "    {\"document\": doc, \"embedding\": embedding}\n",
    "    for doc, embedding in zip(documents_valides, embeddings)\n",
    "]\n",
    "\n",
    "# Calculer la similarité cosinus entre les embeddings\n",
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 3))\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(informations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction qui cherche les documents les plus pertinents pour une requête\n",
    "def recherche(query, tfidf_vectorizer, tfidf_matrix, embeddings, documents, model):\n",
    "    # Si la requête contient des mots-clés, on effectue une recherche par mots-clés\n",
    "    if detecter_recherche_par_mots_cles(query):\n",
    "        return [res[0] for res in recherche_par_mots_cles(query, documents)]\n",
    "    else:\n",
    "        return recherche_hybride(query, tfidf_vectorizer, tfidf_matrix, embeddings, documents, model)\n",
    "\n",
    "# Fonction qui permet de détecter si la requête est une recherche par mots-clés\n",
    "def detecter_recherche_par_mots_cles(query):\n",
    "    termes_indicateurs = [\"liés à\", \"documents sur\", \"articles sur\", \"mots-clés\", \"thème\", \"traitent de\", \"traitant de\", \"concernant\", \"par rapport à\"]\n",
    "    return any(terme in query.lower() for terme in termes_indicateurs)\n",
    "\n",
    "# Fonction qui recherche les documents par mots-clés\n",
    "def recherche_par_mots_cles(query, documents):\n",
    "    resultats = []\n",
    "    for doc in documents:\n",
    "        mots_cles = doc.get('keyword_s', []) + doc.get('extracted_keywords', []) # On se concentre sur tous les mots-clés\n",
    "        similarite = sum(1 for mot in mots_cles if mot.lower() in query.lower())\n",
    "        if similarite > 0:\n",
    "            resultats.append((doc, similarite))\n",
    "    return sorted(resultats, key=lambda x: x[1], reverse=True)[:10]  # Trier par pertinence\n",
    "\n",
    "# Fonction qui recherche les documents avec une combinaison de similarité sémantique et TF-IDF\n",
    "def recherche_hybride(query, tfidf_vectorizer, tfidf_matrix, embeddings, documents, model):\n",
    "    # Recherche sémantique avec embeddings\n",
    "    query_embedding = model.encode(query, convert_to_tensor=True)\n",
    "    similarites_sémantiques = cosine_similarity(query_embedding, embeddings)\n",
    "    \n",
    "    # Recherche TF-IDF\n",
    "    tfidf_query = tfidf_vectorizer.transform([query])\n",
    "    similarites_tfidf = tfidf_cosine_similarity(tfidf_query, tfidf_matrix)\n",
    "\n",
    "    # Recherche par mots-clés\n",
    "    scores_keywords = []\n",
    "    for doc in documents:\n",
    "        mots_cles = doc.get('keyword_s', []) + doc.get('extracted_keywords', [])\n",
    "        scores_keywords.append(sum(1 for mot in mots_cles if mot.lower() in query.lower()))\n",
    "    \n",
    "    # Combinaison des scores\n",
    "    # Attention : `similarites_tfidf` est 2D, donc on prend le vecteur [0]\n",
    "    scores_combines = (0.3 * similarites_sémantiques + 0.6 * similarites_tfidf[0] + 0.1 * torch.tensor(scores_keywords))\n",
    "\n",
    "    # Tri des résultats par pertinence\n",
    "    indices_tries = scores_combines.argsort(descending=True)  # Indices triés par score\n",
    "    return [documents[i] for i in indices_tries[:10]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Titre: ['Vers la généralisation de l’apprentissage par renforcement', 'Toward the generalization of reinforcement learning'], Mots-clés: ['Reinforcement learning', 'Multimodal agents', 'Exploration', 'General-purpose agent', 'Sparsely rewarded environments', 'Apprentissage par renforcement', 'Agents multimodaux', 'Exploration', 'Agent à usage général', 'Environnements à récompenses rares'], Auteurs: ['Quentin Gallouédec']\n",
      "Titre: ['Étude de la motivation intrinsèque en apprentissage par renforcement'], Mots-clés: ['Reinforcement learning', 'Intrinsic motivation', 'Curiosity', 'Knowledge acquisition', 'Options', 'Generation of objectives', 'Meta-reward', 'Apprentissage par renforcement', 'Motivation intrinsèque', 'Curiosité', 'Acquisition de connaissances', 'Empowerment', 'Options', \"Génération d'objectifs\"], Auteurs: ['Arthur Aubret', 'Laëtitia Matignon', 'Salima Hassas']\n",
      "Titre: ['Learning increasingly complex skills through deep reinforcement learning using intrinsic motivation', \"Apprentissage de compétences de plus en plus complexes via l'apprentissage profond par renforcement en utilisant la motivation intrinsèque\"], Mots-clés: ['Reinforcement learning', 'Intrinsic motivation', 'Developmental learning', 'Lifelong learning', 'Representation learning', 'Apprentissage par renforcement', 'Motivation intrinsèque', 'Apprentissage développemental', \"Apprentissage tout au long d'une vie\", 'Apprentissage de représentations'], Auteurs: ['Arthur Aubret']\n",
      "Titre: ['Apprentissage adaptatif de comportements éthiques'], Mots-clés: ['Ethics', 'Reinforcement Learning', 'Multi-Agent Systems', 'Energy management', 'Éthique', 'Apprentissage par renforcement', 'Systèmes Multi-Agent', \"Répartition de l'énergie\"], Auteurs: ['Rémy Chaput', 'Olivier Boissier', 'Mathieu Guillermin', 'Salima Hassas']\n",
      "Titre: ['IHM avancées pour l’apprentissage'], Mots-clés: [''], Auteurs: ['Audrey Serna', 'Sébastien George']\n",
      "Titre: ['Automatic learning of next generation human-computer interactions', 'Apprentissage automatique des interactions homme-machine de la prochaine génération'], Mots-clés: ['Computer science', 'Machine learning', 'Human computer interaction', 'Deep Learning', 'Supervised learning', 'Reinforcement learning', 'Unsupervised learning', 'Adaptive interface', 'User interface', 'Informatique', 'Apprentissage automatique', 'Interaction Homme-Machine', 'Apprentissage profond', 'Apprentissage supervisé', 'Apprentissage par renforcement', 'Apprentissage non supervisé', 'Interface adaptative', 'Interface utilisateur', 'Interactions Homme Machine'], Auteurs: ['Quentin Debard']\n",
      "Titre: [\"Vers une meilleure identification d'acteurs de Bitcoin par apprentissage supervisé\"], Mots-clés: [''], Auteurs: ['Rafael Ramos Tubino', 'Rémy Cazabet', 'Céline Robardet']\n",
      "Titre: ['Approche multi-agent combinant raisonnement et apprentissage pour un comportement éthique'], Mots-clés: ['Ethics', 'Machine Ethics', 'Multi-Agent Learning', 'Reinforcement Learning', 'Hybrid Neural-Symbolic Learning', 'Ethical Judgment', 'Éthique', 'Machine Ethics', 'Apprentissage Multi-Agent', 'Apprentissage par Renforcement', 'Hybride Neural-Symbolique', 'Jugement Éthique'], Auteurs: ['Rémy Chaput', 'Jérémy Duval', 'Olivier Boissier', 'Mathieu Guillermin', 'Salima Hassas']\n",
      "Titre: ['Projet EPICEA: Évaluation de Processus Interactif de Capitalisation d’Épisodes d’Apprentissage: application à l’assistance à l’apprentissage en enseignement à distance.'], Mots-clés: [''], Auteurs: ['Magali Ollagnier-Beldame']\n",
      "Titre: [\"Apprentissage séquentiel de compétences via la motivation intrinsèque et l'apprentissage par renforcement\"], Mots-clés: ['Reinforcement learning', 'Skills learning', 'Intrinsic motivation', 'Catastrophique forgetting'], Auteurs: ['Hedwin Bonnavaud', 'Arthur Aubret', 'Laëtitia Matignon']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tomhu\\AppData\\Local\\Temp\\ipykernel_8488\\2562472673.py:42: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  scores_combines = (0.3 * similarites_sémantiques + 0.6 * similarites_tfidf[0] + 0.1 * torch.tensor(scores_keywords))\n"
     ]
    }
   ],
   "source": [
    "# Exemple de requête\n",
    "query = \"Apprentissage par renforcement\"\n",
    "resultats = recherche_hybride(query, tfidf_vectorizer, tfidf_matrix, embeddings, documents, modele)\n",
    "\n",
    "# Afficher les résultats\n",
    "for res in resultats:\n",
    "    print(f\"Titre: {res['title_s']}, Mots-clés: {res['keyword_s']}, Auteurs: {res['authFullName_s']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
