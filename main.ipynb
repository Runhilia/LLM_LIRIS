{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "from torch.nn.functional import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Récupération des données de l'API HAL\n",
    "url = \"https://api.archives-ouvertes.fr/search/\"\n",
    "params = {\n",
    "    'q': 'labStructAcronym_s:\"LIRIS\"',  # Recherche par acronyme de laboratoire\n",
    "    'fl': 'title_s,abstract_s,authFullName_s,producedDateY_i,keyword_s', # Champs à récupérer\n",
    "    'rows': 10000  # Nombre de résultats à récupérer 10000 pour avoir tous les résultats\n",
    "}\n",
    "# Réponse de l'API\n",
    "reponse = requests.get(url, params=params)\n",
    "data = reponse.json()\n",
    "\n",
    "# Récupération des documents\n",
    "documents = data['response']['docs']\n",
    "\n",
    "# Remplacement des valeurs manquantes par des chaînes vides\n",
    "categories = ['title_s', 'abstract_s', 'authFullName_s', 'keyword_s']\n",
    "for doc in documents:\n",
    "    for cat in categories:\n",
    "        if cat not in doc:\n",
    "            doc[cat] = ['']\n",
    "\n",
    "# Ecriture des documents dans un json\n",
    "with open('documents.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(documents, f, ensure_ascii=False, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement du modèle\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Extraction des informations des documents\n",
    "informations = [\n",
    "    f\"{doc.get('title_s', '')} \"  # Titre\n",
    "    f\"{', '.join(doc.get('keyword_s', []))} \"  # Mots-clés\n",
    "    f\"{doc.get('abstract_s', '')} \"  # Abstract\n",
    "    f\"Auteurs: {', '.join(doc.get('authFullName_s', []))} \"  # Auteurs\n",
    "    for doc in documents\n",
    "]\n",
    "\n",
    "# Générer les embeddings\n",
    "embeddings = model.encode(informations, convert_to_tensor=True)\n",
    "\n",
    "# Associer chaque embedding à son document\n",
    "documents_valides = [doc for doc, titre in zip(documents, informations) if titre.strip()]\n",
    "documents_embeddings = [\n",
    "    {\"document\": doc, \"embedding\": embedding}\n",
    "    for doc, embedding in zip(documents_valides, embeddings)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recherche_semantique(query, embeddings, documents, model):\n",
    "    # Générer l'embedding pour la requête utilisateur\n",
    "    query_embedding = model.encode(query, convert_to_tensor=True)\n",
    "\n",
    "    # Calculer la similarité cosinus entre la requête et chaque document\n",
    "    similarites = cosine_similarity(query_embedding, embeddings)\n",
    "\n",
    "    # Trouver les indices des documents les plus pertinents\n",
    "    indices_tries = similarites.argsort(descending=True)\n",
    "\n",
    "    # Retourner les documents triés par pertinence\n",
    "    resultats = [documents[i] for i in indices_tries[:5]]\n",
    "    return resultats\n",
    "\n",
    "# Exemple de requête\n",
    "query = \"Cedric chauve\"\n",
    "resultats = recherche_semantique(query, embeddings, documents_valides, model)\n",
    "\n",
    "# Afficher les résultats\n",
    "for res in resultats:\n",
    "    print(f\"Titre: {res['title_s']}, Mot-clés: {res['keyword_s']}), Auteurs: {res['authFullName_s']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chercher si un auteur a publié plusieurs fois (pour mieux visualiser dans le graphe après)\n",
    "authors = {}\n",
    "for doc in data['response']['docs']:\n",
    "    for author in doc['authFullName_s']:\n",
    "        if author in authors:\n",
    "            authors[author] += 1\n",
    "        else:\n",
    "            authors[author] = 1\n",
    "            \n",
    "for author, count in authors.items():\n",
    "    if count > 1:\n",
    "        print(f\"{author} a publié {count} fois\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G2 = nx.Graph()\n",
    "# Création des noeuds et des arêtes\n",
    "for pub in data['response']['docs']:\n",
    "    # Création du noeud article\n",
    "    title = pub.get('title_s')[0]\n",
    "    year = pub['producedDateY_i']\n",
    "    article_node = f\"Article: {title} ({year})\"\n",
    "    G2.add_node(article_node, type='article', year=year)\n",
    "    \n",
    "    # Création des noeuds auteurs et des arêtes qui relient les auteurs à l'article\n",
    "    authors = pub.get('authFullName_s', [])\n",
    "    for author in authors:\n",
    "        author_node = f\"Auteur: {author}\"\n",
    "        G2.add_node(author_node, type='auteur')\n",
    "        G2.add_edge(article_node, author_node, relation='WRITTEN_BY')\n",
    "    \n",
    "    # Création des noeuds mots-clés et des arêtes qui relient les mots-clés à l'article\n",
    "    keywords = pub.get('keyword_s', [])\n",
    "    for keyword in keywords:\n",
    "        keyword_node = f\"Mot-clé: {keyword}\"\n",
    "        G2.add_node(keyword_node, type='mot-clé')\n",
    "        G2.add_edge(article_node, keyword_node, relation='HAS_KEYWORD')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Nombre de noeuds:', G2.number_of_nodes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation du graphe\n",
    "plt.figure(figsize=(20, 20))\n",
    "pos = nx.spring_layout(G2, k=0.3)\n",
    "node_colors = [\"blue\" if G2.nodes[n][\"type\"] == \"article\" \n",
    "                   else \"red\" if G2.nodes[n][\"type\"] == \"auteur\" \n",
    "                   else \"orange\" for n in G2.nodes()]\n",
    "nx.draw(G2, pos, node_size=20, with_labels=False, node_color=node_colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Récupération des données du LIRIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.firefox.options import Options\n",
    "\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import TimeoutException, StaleElementReferenceException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_page(url):\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        return BeautifulSoup(response.text, \"html.parser\")\n",
    "    else:\n",
    "        print(f\"Erreur {response.status_code} pour {url}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_json(dataG, section, new_data):\n",
    "    if os.path.exists(\"equipes.json\"):\n",
    "        # Lire les données existantes\n",
    "        with open(\"equipes.json\", 'r', encoding='utf-8') as fichier:\n",
    "            try:\n",
    "                contenu = json.load(fichier)\n",
    "            except json.JSONDecodeError:\n",
    "                contenu = {}  # Initialiser comme une liste vide si le fichier est vide ou corrompu\n",
    "    else:\n",
    "        contenu = {}  # Si le fichier n'existe pas, initialiser une liste vide\n",
    "\n",
    "    # Ajouter les nouvelles données\n",
    "    dataG[section] = new_data\n",
    "    contenu.update(dataG)\n",
    "\n",
    "    with open(\"equipes.json\", 'w', encoding='utf-8') as fichier:\n",
    "        json.dump(contenu, fichier, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = fetch_page(\"https://liris.cnrs.fr/recherche/liste-des-equipes\")\n",
    "\n",
    "blocks = page.find_all(\"div\", \"views-row\")\n",
    "\n",
    "data= {}\n",
    "equipes = {}\n",
    "poles = {}\n",
    "\n",
    "for block in blocks:\n",
    "    url = block.find(\"a\")\n",
    "    urlEquipe = \"https://liris.cnrs.fr/\" + url['href']\n",
    "    acronyme = url.text\n",
    "\n",
    "    nomEquipe = block.find(\"i\")\n",
    "\n",
    "    polePrincipal = block.find(\"div\", \"views-field views-field-field-equipel-pole\").find(\"a\")\n",
    "    urlPoleP = \"https://liris.cnrs.fr/\" + polePrincipal['href']\n",
    "    nomPoleP = polePrincipal.text\n",
    "\n",
    "    equipes[acronyme] = {\n",
    "        \"url\": urlEquipe,\n",
    "        \"nom\": nomEquipe.text,\n",
    "        \"poles\": [\n",
    "            {\n",
    "                \"nom\": nomPoleP,\n",
    "                \"type\": \"Principal\"\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    poles[nomPoleP] ={\n",
    "        \"url\": urlPoleP,\n",
    "        \"nom\": nomPoleP\n",
    "    }\n",
    "\n",
    "    poleSecondaires = block.find(\"span\", \"views-field views-field-field-poles-secondaires\")\n",
    "    if poleSecondaires:\n",
    "        poleSecondaires = poleSecondaires.find(\"span\", \"field-content\").find_all(\"a\")\n",
    "\n",
    "        for poleSecondaire in poleSecondaires:\n",
    "            urlPoleS = poleSecondaire['href']\n",
    "            nomPoleS = poleSecondaire.text\n",
    "            equipes[acronyme][\"poles\"].append({\n",
    "                \"nom\": nomPoleS,\n",
    "                \"type\": \"Secondaire\"\n",
    "            })\n",
    "            poles[nomPoleS] = {\n",
    "                \"url\": urlPoleS,\n",
    "                \"nom\": nomPoleS\n",
    "            }\n",
    "\n",
    "update_json(data, \"equipes\", equipes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Description des pôles\n",
    "for pole in poles.keys():\n",
    "    page = fetch_page(poles[pole]['url'])\n",
    "    if page is not None:\n",
    "        description = page.find(\"div\", \"field-items\").text\n",
    "        poles[pole][\"description\"] = description\n",
    "\n",
    "update_json(data, \"poles\", poles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Responsables des équipes\n",
    "for equipe in equipes.keys():\n",
    "    page = fetch_page(equipes[equipe]['url'])\n",
    "    if page is not None:\n",
    "        responsables = page.find_all(\"td\")\n",
    "        responsable = responsables[0].text\n",
    "        responsableAdjoint = responsables[1].text\n",
    "        equipes[equipe][\"responsable\"] = responsable.split(\":\")[1].strip()\n",
    "        equipes[equipe][\"responsableAdjoint\"] = responsableAdjoint.split(\":\")[1].strip()\n",
    "        \n",
    "\n",
    "update_json(data, \"equipes\", equipes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Membres des équipes et description\n",
    "for equipe in equipes.keys():\n",
    "    option = Options()\n",
    "    driver = webdriver.Firefox(options=option)\n",
    "    driver.get(equipes[equipe]['url'])\n",
    "    try:\n",
    "        WebDriverWait(driver, 50).until(\n",
    "            EC.presence_of_element_located((By.CLASS_NAME, \"ev-liris-header-recherche\"))\n",
    "        )\n",
    "        driver.execute_script(\"window.scrollTo(0, 200)\")\n",
    "        \n",
    "        description = driver.find_element(\"xpath\", \"//div[@id='qt-affichage_equipe-ui-tabs1']\")\n",
    "        equipes[equipe][\"description\"] = description.text\n",
    "        \n",
    "        # Aller à l'onglet \"Membres\" et afficher tous les membres\n",
    "        driver.find_element(\"xpath\", \"//a[@href='#qt-affichage_equipe-ui-tabs2']\").click()\n",
    "        driver.find_element(\"xpath\", \"//select[@id='edit-items-per-page']\").click()\n",
    "        driver.find_element(\"xpath\", \"//option[@value='All']\").click()\n",
    "        membresDict = []\n",
    "        # While true car la référence de l'élément peu changer\n",
    "        while True:\n",
    "            try:\n",
    "                membres = driver.find_elements(\"xpath\", \"//table[@class='views-table cols-5 table table-hover table-striped']/tbody/tr\")\n",
    "                for membre in membres:\n",
    "                    if membre.find_element(\"xpath\", \"./td[1]\").text == \"\":\n",
    "                        continue\n",
    "                    prenom = membre.find_element(\"xpath\", \"./td[1]\").text\n",
    "                    nom = membre.find_element(\"xpath\", \"./td[2]\").text\n",
    "                    statut = membre.find_element(\"xpath\", \"./td[3]\").text\n",
    "                    employeur = membre.find_element(\"xpath\", \"./td[4]\").text\n",
    "                    \n",
    "                    membresDict.append({\n",
    "                        \"prenom\": prenom,\n",
    "                        \"nom\": nom,\n",
    "                        \"statut\": statut,\n",
    "                        \"employeur\": employeur\n",
    "                    })\n",
    "                    \n",
    "                    \n",
    "                break  # Si tout s'est bien passé, sortir de la boucle\n",
    "            except StaleElementReferenceException:\n",
    "                print(\"Élément obsolète, relocalisation...\")\n",
    "                continue  # Relocaliser les éléments\n",
    "        \n",
    "        equipes[equipe][\"membres\"] = membresDict\n",
    "    except TimeoutException:\n",
    "        print(\"Chargement de la page trop long\")\n",
    "        continue\n",
    "    driver.quit()\n",
    "    \n",
    "update_json(data, \"equipes\", equipes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "def build_knowledge_graph(equipes):\n",
    "    G = nx.Graph()\n",
    "\n",
    "    # Ajouter les équipes et leurs relations\n",
    "    for equipe in equipes.values():\n",
    "        # Nœud de l'équipe\n",
    "        G.add_node(equipe[\"nom\"], type=\"Équipe\", description=equipe[\"description\"], website=equipe[\"url\"])\n",
    "\n",
    "        # Relation avec les pôles\n",
    "        for pole in equipe[\"poles\"]:\n",
    "            G.add_node(pole[\"nom\"], type=\"Pôle\")\n",
    "            # Relation avec une étiquette Principal/Secondaire\n",
    "            if pole[\"type\"] == \"Principal\":\n",
    "                G.add_edge(equipe[\"nom\"], pole[\"nom\"], relation=\"BELONGS_TO_PRINCIPAL\")\n",
    "            elif pole[\"type\"] == \"Secondaire\":\n",
    "                G.add_edge(equipe[\"nom\"], pole[\"nom\"], relation=\"BELONGS_TO_SECONDARY\")\n",
    "\n",
    "        # Relation avec le responsable et le co-responsable\n",
    "        G.add_node(equipe[\"responsable\"], type=\"Personne\", role=equipe[\"responsable\"])\n",
    "        G.add_edge(equipe[\"nom\"], equipe[\"responsable\"], relation=\"HAS_RESPONSIBLE\")\n",
    "\n",
    "        G.add_node(equipe[\"responsableAdjoint\"], type=\"Personne\", role=equipe[\"responsableAdjoint\"])\n",
    "        G.add_edge(equipe[\"nom\"], equipe[\"responsableAdjoint\"], relation=\"HAS_CO_RESPONSIBLE\")\n",
    "\n",
    "       \n",
    "        # Ajouter les membres\n",
    "        for member in equipe[\"membres\"]:\n",
    "            G.add_node(member[\"nom\"], type=\"Membre\", status=member[\"statut\"], institute=member[\"employeur\"])\n",
    "            G.add_edge(member[\"nom\"], equipe[\"nom\"], relation=\"MEMBER_OF\")\n",
    "\n",
    "    return G\n",
    "\n",
    "knowledge_graph = build_knowledge_graph(equipes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dessiner le graphe\n",
    "pos = nx.spring_layout(knowledge_graph)\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# Dessiner les nœuds\n",
    "nx.draw_networkx_nodes(knowledge_graph, pos, node_size=5, node_color=\"lightblue\")\n",
    "\n",
    "# Dessiner les relations\n",
    "nx.draw_networkx_edges(knowledge_graph, pos, edgelist=knowledge_graph.edges(), edge_color=\"gray\")\n",
    "\n",
    "# Ajouter les étiquettes\n",
    "# node_labels = nx.get_node_attributes(knowledge_graph, \"type\")\n",
    "# nx.draw_networkx_labels(knowledge_graph, pos, labels={node: node for node in knowledge_graph.nodes()})\n",
    "\n",
    "# edge_labels = nx.get_edge_attributes(knowledge_graph, \"relation\")\n",
    "# nx.draw_networkx_edge_labels(knowledge_graph, pos, edge_labels=edge_labels)\n",
    "\n",
    "plt.title(\"Graphe de connaissances\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
